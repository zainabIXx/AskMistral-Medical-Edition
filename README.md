This medical chatbot leverages a retrieval-augmented generation pipeline combining FAISS-based semantic search over vectorized medical documents with the Mistral-7B-Instruct LLM hosted on HuggingFace. User queries are embedded using sentence-transformers and matched against a FAISS index of chunked PDF medical texts, providing relevant context that guides the LLMâ€™s response generation. The system is built on Streamlit for an interactive chat interface, uses LangChain to orchestrate document loading, chunking, retrieval, and prompting, and enforces strict prompt templates to ensure fact-based, context-grounded answers, delivering a scalable, transparent, and reliable AI assistant for medical information.
